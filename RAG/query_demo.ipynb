{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [phoenix.session.session] Existing running Phoenix instance detected! Shutting it down and starting a new instance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "ğŸ“– For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "px.launch_app()\n",
    "import llama_index.core\n",
    "\n",
    "llama_index.core.set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# è·å–é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname('__file__'), \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "embed_model must start with str 'local' or of type BaseEmbedding",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mModelScopeEmbeddings4LlamaIndex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelScopeEmbeddings4LlamaIndex\n\u001b[1;32m      9\u001b[0m Settings\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m OpenAILike(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqwen2\u001b[39m\u001b[38;5;124m\"\u001b[39m, api_base\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://192.168.100.111:8000/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mSettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_model\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miic/nlp_gte_sentence-embedding_chinese-base\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.11/site-packages/llama_index/core/settings.py:77\u001b[0m, in \u001b[0;36m_Settings.embed_model\u001b[0;34m(self, embed_model)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;129m@embed_model\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, embed_model: EmbedType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set the embedding model.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_embed_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.11/site-packages/llama_index/core/embeddings/utils.py:103\u001b[0m, in \u001b[0;36mresolve_embed_model\u001b[0;34m(embed_model, callback_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m model_name \u001b[38;5;241m=\u001b[39m splits[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(splits) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_local \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membed_model must start with str \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or of type BaseEmbedding\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m     )\n\u001b[1;32m    107\u001b[0m cache_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(get_cache_dir(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(cache_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: embed_model must start with str 'local' or of type BaseEmbedding"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai_like import OpenAILike\n",
    "\n",
    "# å¦‚æœé¡¹ç›®æ ¹ç›®å½•ä¸åœ¨ç³»ç»Ÿè·¯å¾„ä¸­ï¼Œåˆ™å°†å…¶æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„ä¸­\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# å¯¼å…¥è‡ªå®šä¹‰çš„ ModelScopeEmbeddings4LlamaIndex æ¨¡å‹åµŒå…¥ç±»\n",
    "from utils.ModelScopeEmbeddings4LlamaIndex import ModelScopeEmbeddings4LlamaIndex\n",
    "Settings.llm = OpenAILike(model=\"qwen2\", api_base=\"http://192.168.100.111:8000/v1\", api_key=\"dummy\", max_tokens=100)\n",
    "Settings.embed_model = \"iic/nlp_gte_sentence-embedding_chinese-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
